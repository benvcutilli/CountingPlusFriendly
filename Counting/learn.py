# Comments that apply to multiple locations; they are pointed to with the notation "(#)" in this
# file:
#    (1) Added the momentum version of SGD for the convergence issue using Sigmoids mentioned in the
#        comment for Convolutional in networks.py.
#    (2) RMSprop[88c6d0, slide "6e" up to (non-inclusive) last slide] was added to this code; however, it may be the case that Chainer
#        doesn't implement this properly as [3c31a8, RMSpropRule.update_core_cpu(...)] shows no point at which the step size
#        gets bigger after successive gradients with the same sign, as prescribed in
#        [88c6d0, slide "6e" up to (non-inclusive) last slide] (although, that reference may not actually want such
#        functionality; it isn't clear). Trying this optimizer because of the changes outlined in
#        networks.py to the "Convolutional" network (also in networks.py); since Sigmoid activation
#        functions were used at the time, the network was likely not learning well due to vanishing
#        gradients. [88c6d0, slide "6e" up to (non-inclusive) last slide] had mentioned that it could more easily handle these plateaus, so
#        I gave it a shot (even [3c31a8, RMSpropRule.update_core_cpu(...)]'s implementation, if not the same as [88c6d0, slide "6e" up to (non-inclusive) last slide]
#        intended, would do that as small successive gradients will cause steps as large as bigger
#        successive gradients would; this is because, as stated in [88c6d0, slide "6e" up to (non-inclusive) last slide], this sequence of
#        similar-magnitude gradients woud mean that the square root of the weighted average would be
#        equal in magnitude to the current gradient, so the division of the gradient by that square
#        root value would be roughly 1, regardless of how large or small the running average is).
#        However, this ended up not helping.







# From [38e732]
import argparse

# Chainer[170ecf]
import chainer
chainer.backends.cuda.set_max_workspace_size(200000000)

# [889500] module
import pathlib

# Importing [61fceb]
import json

# The [7c779f] module
import math

# collections module[658323]
import collections

import networks
import common
from replacementiterator import FreeFlowIterator











argumentParser = argparse.ArgumentParser()

argumentParser.add_argument("model",
                            type=str,
                            help="Which model to train (defined in networks.py, named in the \
                                 comments above them)",
                            choices=["convolutional", "convolutionallarge"])
# "pureChainerMSP", "modifiedSoftPlus", "sin", "relu", and "sigmoid" refer to (and uses the names
# of) networks.pureChainerMSP, networks.modifiedSoftPlus, [13668a], ^^chainerrelu^^^ (which
# implements [bffa08]), and [79c583], respectively. "softplus" refers to
# [cf158f]. See the README for why these functions are used.
argumentParser.add_argument("activation",
                            type=str,
                            help="The activation function of the network",
                            choices=["pureChainerMSP",
                                     "modifiedSoftPlus",
                                     "sin",
                                     "relu",
                                     "sigmoid",
                                     "softplus"])
argumentParser.add_argument("datasetPath",
                            type=str,
                            help="The folder that contains the dataset and truths.json \
                                 generated by sampler.py")
argumentParser.add_argument("saveFolder",
                            type=str,
                            help="Path to the folder in which anything training-related will \
                                 be saved")
argumentParser.add_argument("howManyShapeTypes",
                            type=int,
                            help="The number of outputs that the neural network should have")
# See comments (1) and (2)
argumentParser.add_argument("--optimizer",
                            type=str,
                            default="sgd",
                            help="The optimizer to use; choose between Stochastic Gradient \
                                 Descent (\"sgd\"), Stochastic Gradient Descent with momentum \
                                 (\"momentum\"), or RMSprop (\"rmsprop\"); will use Chainer's \
                                 implementation to do this",
                            choices=["sgd", "momentum", "rmsprop"])
# The options that follow have been made to have the same format (with the hyphens and all
# lower-case, values following them; that last one comes with the ArgumentParser class) that is
# found commonly throughout the command line world.
#
# The default value here is chosen to minimize the stress on the CPU as far as how many threads or
# processes are running simultaneously, as requested by Bruce Shei[f8aaea] (the specific
# number probably wasn't requested, though)
argumentParser.add_argument("--workers",
                           type=int,
                           default=8,
                           help="Sets how many threads are used to load the data")
# The optimizers discussed in (1) and (2) use this value
argumentParser.add_argument("--learning-rate",
                           type=float,
                           default=0.07,
                           help="Learning rate to use while training")
# (1) applies to this option
argumentParser.add_argument("--momentum",
                            type=float,
                            default=0.85,
                            help= "The momentum you'd like to use (only applicable when using \
                                    momentum during Stochastic Gradient Descent)")
argumentParser.add_argument("--epochs",
                            type=int,
                            default=100,
                            help="Number of epochs to run for")
argumentParser.add_argument("--samples-per-iteration",
                            type=int,
                            default=20,
                            help="How many samples you want each iteration to process")
argumentParser.add_argument("--plot-start",
                            type=int,
                            default=0,
                            help="What iteration at which the program should begin to plot \
                                 loss during training")
argumentParser.add_argument("--save-every",
                            type=int,
                            default=10,
                            help="How many epochs elapse between model save")
argumentParser.add_argument("--base",
                            type=float,
                            default=1.1,
                            help="Base used in the \"convolutional\" neural network of \
                                 networks.py for the ModifiedSoftPlus(...) activation function \
                                 in that same file (see networks.py for details)")
# "settings.json" refers to the file created just before training begins (the code for that is
# towards the bottom of this file)
argumentParser.add_argument("--notes",
                            type=str,
                            help="Anything you would like to add to the settings.json file \
                                 output to saveFolder")

# This argument is regarding Batch Renormalization[e1d64c]
argumentParser.add_argument("--renormalize",
                            action="store_true",
                            help="Use Batch Renormalization")
# Full reference for the webpage found in the help string: [5b1d7a]. The idea
# of having a command line parameter that can control which device is used is from something
# that I had done previously; maybe it was from when I had tried to write this project
# before.
argumentParser.add_argument("--device",
                            type=str,
                            default="@numpy",
                            help="Which device you want to run on; this is a \"device \
                            specifier\" from https://docs.chainer.org/en/stable/reference/gener\
                            ated/chainer.get_device.html)")

parameters = argumentParser.parse_args()




# Changes the values of rmax and dmax, which are attributes of
# chainer.links.BatchRenormalization[7ca151]. The rmax and dmax values
# of that class are set to increasingly higher values (though only slightly higher), as
# recommended by [e1d64c].
class RMaxDMaxModifier(chainer.training.Extension):

    def __init__(self):
        super().__init__()

        self.trigger = (1, "epoch")
        self.rmaxQueue = collections.deque()
        self.dmaxQueue = collections.deque()

        self.rmaxQueue.append(1.1)
        self.rmaxQueue.append(10)
        self.rmaxQueue.append(100)
        self.rmaxQueue.append(1000)

        self.dmaxQueue.append(1.1)
        self.dmaxQueue.append(10)
        self.dmaxQueue.append(100)
        self.dmaxQueue.append(1000)

        self.lossThreshold       = 3.0
        self.lossAchieved        = False
        self.lastEpoch           = 0
        self.epochsBetweenChange = 20

    # Using the same parameter name as chainer.training.Extension's[a4f797]
    # .__call__(...) just because I can't think of anything better
    def __call__(self, trainer):

        case1 = ((trainer.updater.get_optimizer("main").target.loss.data < self.lossThreshold) \
                                              and                                              \
                                    (not self.lossAchieved))

        case2 = (trainer.updater.epoch - self.lastEpoch >= self.epochsBetweenChange)           \
                                              and                                              \
                                        self.lossAchieved


        if (case1 or case2) and len(self.rmaxQueue) != 0:
            dmaxReplacement = self.dmaxQueue.popleft()
            rmaxReplacement = self.rmaxQueue.popleft()
            for layer in trainer.updater.get_optimizer("main").target.predictor.children():
                if isinstance(layer, chainer.links.BatchRenormalization):
                    layer.rmax = rmaxReplacement
                    layer.dmax = dmaxReplacement
                    print("chainer.links.BatchRenormalization's dmax/rmax have been changed \
                          to {} and {}, respectively".format(dmaxReplacement, rmaxReplacement))

        if case1:
            self.lossAchieved = True
        if case1 or case2:
            self.lastEpoch    = trainer.updater.epoch











DEVICE = parameters.device

with chainer.using_device(DEVICE):


    # Loading the dataset
    samples = common.shapeDataset(parameters.datasetPath)

    # Loading model
    ################################################################################################
    #                                                                                              #

    toTrain = chainer.links.Classifier(common.getEmptyModel(
                                                parameters.model,
                                                parameters.activation,
                                                parameters.base,
                                                parameters.renormalize,
                                                parameters.howManyShapeTypes),
                                      chainer.functions.mean_squared_error,
                                      chainer.functions.mean_squared_error,
                                      1)

    #                                                                                              #
    ################################################################################################

    # Optimization class instance selection and creation
    ################################################################################################
    #                                                                                              #

    optimizer = None
    if parameters.optimizer == "sgd":
        optimizer = chainer.optimizers.SGD(parameters.learning_rate)

    # Rationale for this optimizer is discussed in (1), and in (2) for the "rmsprop" case
    ################################################################################################
    #                                                                                              #

    if parameters.optimizer == "momentum":
        optimizer = chainer.optimizers.MomentumSGD(parameters.learning_rate, parameters.momentum)
    if parameters.optimizer == "rmsprop":
        # Leaving the "alpha" parameter[083483] unchanged from default because I
        # couldn't get my own alpha to work correctly
        optimizer = chainer.optimizers.RMSprop(parameters.learning_rate)

    #                                                                                              #
    ################################################################################################

    optimizer.setup(toTrain)

    #                                                                                              #
    ################################################################################################

    # In one of my original PyTorch[05c8ff] implementations, I used a
    # Queue[9f139d, the Queue class] to allow worker processes to move data from themselves to the
    # process that does the main part of training. The Queue and the workers themselves were
    # inspired by [05c8ff]'s use of them (or some page under that page).
    itr = chainer.iterators.MultiprocessIterator(samples,
                                                parameters.samples_per_iteration,
                                                n_processes=parameters.workers,
                                                n_prefetch=50,
                                                shuffle=True)

    # itr = FreeFlowIterator(parameters.workers, True, samples, parameters.samples_per_iteration)

    updater = chainer.training.StandardUpdater(itr, optimizer, device=DEVICE)

    trainer = chainer.training.Trainer(updater,
                                       out=parameters.saveFolder,
                                       stop_trigger=(parameters.epochs, "epoch"))



    iterations = parameters.epochs * math.ceil(len(samples) / parameters.samples_per_iteration)

    def modifyGraph(figure, axes, dictSummary):
        axes.set_xbound(0, iterations)
        axes.set_ybound(0, 200)

    plotTriggerList   = list(range(parameters.plot_start, iterations, 100))
    recordTriggerList = list(range(parameters.plot_start, iterations, 1))
    plotTrigger       = chainer.training.triggers.ManualScheduleTrigger(plotTriggerList,
                                                                        "iteration")
    recordTrigger     = chainer.training.triggers.ManualScheduleTrigger(recordTriggerList,
                                                                        "iteration")
    # Commented out due to a "Fail to allocate bitmap" message and parent process kill that appears
    # to be a Matplotlib error according to [9858b9, page title]                                                                   "iteration")
    #trainer.extend(chainer.training.extensions.PlotReport(y_keys=["main/loss"],
    #                                                     filename="loss.png",
    #                                                     marker=None,
    #                                                     trigger=plotTrigger,
    #                                                     postprocess=modifyGraph),
    #               trigger=recordTrigger)



    # Including the iteration number and epoch number, originally displayed by
    # ProgressBar[f58355], because I am replacing ProgressBar with the PrintReport
    # held in display and need to still see the iteration and epoch that I could originally see with
    # ProgressBar.
    ################################################################################################
    #                                                                                              #

    logReport = chainer.training.extensions.LogReport(["main/loss", "iteration", "epoch"],
                                                          trigger=(100, "iteration"),
                                                          filename=None)
    display = chainer.training.extensions.PrintReport(["main/loss", "epoch", "iteration"],
                                                      log_report="stats")
    trainer.extend(logReport, name="stats")
    trainer.extend(display, trigger=(100, "iteration"))

    #                                                                                              #
    ################################################################################################


    # The common practice of adjusting the learning rate to smaller values as training progresses.
    # This will let us descend down narrower minima.
    # trainer.extend(chainer.training.extensions.MultistepShift("lr",
    #                                                          0.1,
    #                                                          [5000, 20000, 40000],
    #                                                          init=None))
    trainer.extend(chainer.training.extensions.StepShift("lr",
                                                         0.1,
                                                         int(iterations / 3)))


    trainer.extend(chainer.training.extensions.snapshot_object(toTrain.predictor,
                                                               "trained" + parameters.model + \
                                                                                            ".npz"),
                   trigger=(parameters.save_every, "epoch"))

    trainer.extend(RMaxDMaxModifier(), priority=chainer.training.PRIORITY_READER)

    # I may have used this idea (or heard of it from) elsewhere[71bd98], but I am saving the
    # values passed in through the command line to a JSON[a2a49d] file in the folder that the
    # neural network is saved in.
    ################################################################################################
    #                                                                                              #

    settingsFile = open(pathlib.Path(parameters.saveFolder, "settings.json"), "w")
    # Calling vars(...)[4ee6c6, vars(...) section] on a Namespace instance[38e732, "The Namespace object"] to get a
    # mapping object is an idea from [38e732, "The Namespace object"]
    json.dump(vars(parameters), settingsFile, indent=3)
    settingsFile.close()

    #                                                                                              #
    ################################################################################################

    trainer.run()

